{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Nextflow Patterns","text":"<p>This page collects some recurring implementation patterns used in Nextflow applications. Feel free to contribute by opening a pull request in the GitHub repository.</p>"},{"location":"channel-duplication/","title":"Channel duplication","text":""},{"location":"channel-duplication/#problem","title":"Problem","text":"<p>You need to you use the same channel as input in two or more processes.</p>"},{"location":"channel-duplication/#solution","title":"Solution","text":"<p>In DSL2, you can just do it! The into operator is no longer needed.</p>"},{"location":"channel-duplication/#code","title":"Code","text":"<pre><code>process foo {\n  input: path x\n  script: \n  \"\"\"\n  echo your_command --input $x\n  \"\"\"\n}    \n\nprocess bar {\n  input: path x\n  script: \n  \"\"\"\n  echo your_command --input $x\n  \"\"\"\n}    \n\nworkflow {\n  input_ch = Channel.fromPath(\"$baseDir/data/prots/*_?.fa\")\n\n  foo(input_ch)\n  bar(input_ch)\n}\n</code></pre>"},{"location":"channel-duplication/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code>nextflow run nextflow-io/patterns/channel-duplication.nf\n</code></pre>"},{"location":"collect-into-file/","title":"Collect outputs into a file","text":""},{"location":"collect-into-file/#problem","title":"Problem","text":"<p>You need to concatenate into a single file all output files produced by an upstream process. </p>"},{"location":"collect-into-file/#solution","title":"Solution","text":"<p>Use the collectFile operator to merge all the output files into a single file. </p>"},{"location":"collect-into-file/#code","title":"Code","text":"<pre><code>process foo {\n  input:\n  path x\n  output:\n  path 'file.fq'\n  script:\n  \"\"\"\n  &lt; $x zcat &gt; file.fq\n  \"\"\"\n}\n\nworkflow {\n  Channel.fromPath(\"$baseDir/data/reads/*_1.fq.gz\", checkIfExists: true) \\\n    | foo \\\n    | collectFile \\\n    | view\n}\n</code></pre>"},{"location":"collect-into-file/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code>nextflow run nextflow-io/patterns/collect-into-file.nf\n</code></pre>"},{"location":"conditional-process-dynamic/","title":"Conditional process execution (dynamic)","text":""},{"location":"conditional-process-dynamic/#problem","title":"Problem","text":"<p>One of two processes should be executed depending on the result of an upstream channel.</p>"},{"location":"conditional-process-dynamic/#solution","title":"Solution","text":"<p>Because the condition is a channel result, <code>if/else</code> cannot be used. Instead, use the <code>branch</code> operator to create a \"true\" channel and a \"false\" channel. The channel whose condition is true will receive a value, which will trigger its respective process.</p>"},{"location":"conditional-process-dynamic/#code","title":"Code","text":"<pre><code>process foo {\n    input:\n    val signal\n    output: \n    path 'x.txt'\n\n    script:\n    '''\n    echo foo &gt; x.txt\n    '''\n}\n\nprocess bar {\n    input:\n    val signal\n    output: \n    path 'x.txt'\n\n    script:\n    '''\n    echo bar &gt; x.txt\n    '''\n}\n\nworkflow {\n    ch_if = Channel.of( 1..100 )\n      | randomSample(1)\n      | branch { n -&gt;\n        TRUE: n &gt; 50\n        FALSE: n &lt;= 50\n      }\n\n    ch_if.TRUE | foo\n    ch_if.FALSE | bar\n}\n</code></pre>"},{"location":"conditional-process-dynamic/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code>nextflow run nextflow-io/patterns/conditional-process3.nf\n</code></pre> <p>The workflow will execute <code>foo</code> or <code>bar</code> based on a random number. Execute it multiple times to observe the random behavior.</p>"},{"location":"conditional-process/","title":"Conditional process execution (static)","text":""},{"location":"conditional-process/#problem","title":"Problem","text":"<p>One of two different tasks should be executed based on some condition,  and a third task should process the results of the selected task.</p>"},{"location":"conditional-process/#solution","title":"Solution","text":"<p>Simply execute either process using <code>if/else</code> statements on the condition. Define a channel, e.g. <code>omega_ch</code>, which emits the output of the selected process  in each case. Then, execute the third process with this output channel.</p> <p>Or, use a ternary expression and a pipe to keep things short and sweet.</p>"},{"location":"conditional-process/#code","title":"Code","text":"<pre><code>params.flag = false \n\nprocess foo {\n  output: \n  path 'x.txt'\n\n  script:\n  '''\n  echo foo &gt; x.txt\n  '''\n}\n\nprocess bar {\n  output: \n  path 'x.txt'\n\n  script:\n  '''\n  echo bar &gt; x.txt\n  '''\n}\n\nprocess omega {\n  debug true\n  input:\n  path x\n\n  script:\n  \"\"\"\n  cat $x \n  \"\"\"\n}\n\nworkflow {\n  // the long way\n  if ( params.flag ) {\n    bar()\n    omega_ch = bar.out\n  }\n  else {\n    foo()\n    omega_ch = foo.out\n  }\n\n  omega(omega_ch)\n\n  // the short way\n  (params.flag ? bar : foo) | omega\n}\n</code></pre>"},{"location":"conditional-process/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code>nextflow run nextflow-io/patterns/conditional-process.nf\n</code></pre> <p>The processes <code>foo</code> and <code>omega</code> are executed. Run the same command  with the <code>--flag</code> command line option. </p> <pre><code>nextflow run nextflow-io/patterns/conditional-process.nf --flag \n</code></pre> <p>This time the processes <code>bar</code> and <code>omega</code> are executed.</p>"},{"location":"conditional-process/#alternative-solution","title":"Alternative solution","text":"<p>Create an input channel for each process that is either populated with data or an empty channel. Each process will execute only if its input channel has data.</p> <p>Then use the mix operator to create  a new channel that emits the outputs produced by the two processes, and use it as the input for the third process.</p>"},{"location":"conditional-process/#code_1","title":"Code","text":"<pre><code>params.flag = false\n\nprocess foo {\n  input:\n  val x\n\n  output:\n  path 'x.txt'\n\n  script:\n  \"\"\"\n  echo $x &gt; x.txt\n  \"\"\"\n}\n\nprocess bar {\n  input:\n  val(b)\n\n  output:\n  path 'x.txt'\n\n  script:\n  \"\"\"\n  echo $b &gt; x.txt\n  \"\"\"\n}\n\nprocess omega {\n  debug true\n  input:\n  path x\n\n  script:\n  \"\"\"\n  cat $x\n  \"\"\"\n}\n\nworkflow {\n  (foo_ch, bar_ch) = params.flag\n    ? [ Channel.empty(), Channel.from(1,2,3) ]\n    : [ Channel.from(4,5,6), Channel.empty() ]\n\n  foo(foo_ch)\n  bar(bar_ch)\n\n  foo.out | mix(bar.out) | omega\n}\n</code></pre>"},{"location":"conditional-process/#run-it_1","title":"Run it","text":"<pre><code>nextflow run nextflow-io/patterns/conditional-process2.nf\n</code></pre>"},{"location":"conditional-resources/","title":"Conditional process resources","text":""},{"location":"conditional-resources/#problem","title":"Problem","text":"<p>A task in your workflow needs to use some amount of computing  resources (e.g. memory) that depends on the size or the name of one  or more input files. </p>"},{"location":"conditional-resources/#solution","title":"Solution","text":"<p>Declare the resource requirements (<code>memory</code>, <code>cpus</code>, etc.) in a dynamic manner using a closure. </p> <p>The closure computes the required amount of resources using the file  attributes (e.g. <code>size</code>) of the inputs declared in the process definition.</p>"},{"location":"conditional-resources/#code","title":"Code","text":"<pre><code>process foo {\n    memory { reads.size() &lt; 70.KB ? 1.GB : 5.GB }\n\n    input:\n    path reads\n\n    \"\"\"\n    echo your_command_here --in ${reads} --mem=${task.memory.giga}\n    \"\"\"\n}\n\nworkflow {\n    Channel.fromPath(\"$baseDir/data/reads/*_1.fq.gz\", checkIfExists:true) \\\n        | foo\n}\n</code></pre>"},{"location":"conditional-resources/#run-it","title":"Run it","text":"<pre><code>nextflow run nextflow-io/patterns/conditional-resources.nf\n</code></pre>"},{"location":"create-key-to-combine-channels/","title":"Create key to combine channels","text":""},{"location":"create-key-to-combine-channels/#problem","title":"Problem","text":"<p>You have channels you want to combine, but the elements in these channels are related and you want this new combined channel to take this into consideration. Some Nextflow channel operators can combine elements in channels according to a matching key but, unfortunately, in your case you have no such key.</p>"},{"location":"create-key-to-combine-channels/#solution","title":"Solution","text":"<p>Use the map operator and the <code>toString</code> and <code>split</code> native Groovy functions to extract a matching key from every element of your channel. Then, use the combine operator to combine the channels according to the created matching key.</p> <p>The code below will create sample channels to test the solution.</p> <pre><code>Channel\n  .of('demux.Clontech_5p--bc1003_3p.flnc_clustered.sorted.sam',\n      'demux.Clontech_5p--bc1001_3p.flnc_clustered.sorted.sam',\n      'demux.Clontech_5p--bc1002_3p.flnc_clustered.sorted.sam')\n  .set { ch_alignment }\n\nChannel\n  .of('demux.Clontech_5p--bc1001_3p.flnc_clustered.fasta',\n      'demux.Clontech_5p--bc1002_3p.flnc_clustered.fasta',\n      'demux.Clontech_5p--bc1003_3p.flnc_clustered.fasta')\n  .set { ch_clustered }\n</code></pre>"},{"location":"create-key-to-combine-channels/#code","title":"Code","text":"<pre><code>ch_alignment\n  // For every element of this channel, convert it to a string, split in pieces separated by --, get the second part, then split by _3p and get the first part. Return a list with this as the first value, and then the original element as the second value. This part has to be customized depending on what part of the String you want to get as matching key\n  .map { [it.toString().split(\"--\")[1].split(\"_3p\")[0],\n          it] }.\n  set { ch_alignment }\nch_clustered\n  .map { [it.toString().split(\"--\")[1].split(\"_3p\")[0],\n          it] }.\n  set { ch_clustered }\n\nch_alignment\n  // Combine according to a key that is the first value of every first element, which is a list according to what we did above\n  .combine(ch_clustered, by: 0)\n  // For every element of this channel, which consists of three values now, the matching key (id), the first element of the first channel, and the second, keep only the second and the third.\n  .map { id, sam, fasta -&gt; [sam, fasta] }\n  // View the content of the channel, which consists of the last two values\n  .view()\n</code></pre>"},{"location":"create-key-to-combine-channels/#run-it","title":"Run it","text":"<p>Run the example using this command:</p> <pre><code>nextflow run nextflow-io/patterns/create-key-to-combine-channels.nf\n</code></pre>"},{"location":"feedback-loop/","title":"Feedback loop","text":""},{"location":"feedback-loop/#problem","title":"Problem","text":"<p>You need to repeat a process or workflow multiple times, using the output from the previous iteration as the input to the next iteration.</p>"},{"location":"feedback-loop/#solution","title":"Solution","text":"<p>Warning</p> <p>This feature is experimental and may change in the future.</p> <p>Use the <code>recurse</code> method on a process or workflow to execute it iteratively. In order to use this feature, the process or workflow must have identical input and output definitions, and any initial values must be Groovy values or value channels -- queue channels are not supported (yet).</p> <p>You can use the <code>times</code> operator to perform a fixed number of iterations, or the until operator to iterate until some condition is satisfied.</p>"},{"location":"feedback-loop/#code","title":"Code","text":"<p>For an iterative process:</p> <pre><code>nextflow.preview.recursion=true\n\nparams.data = \"$baseDir/data/hello.txt\"\n\nprocess foo {\n  input:\n    path 'input.txt'\n  output:\n    path 'result.txt'\n  script:\n    \"\"\"\n    cat input.txt &gt; result.txt\n    echo \"Task ${task.index} was here\" &gt;&gt; result.txt\n    \"\"\"\n}\n\nworkflow {\n  // perform a fixed number of iterations\n  foo\n    .recurse(file(params.data))\n    .times(10)\n\n  // iterate until some condition is satisfied\n  foo\n    .recurse(file(params.data))\n    .until { it -&gt; it.size() &gt; 100 }\n\n  foo\n    .out\n    .view(it -&gt; it.text)\n}\n</code></pre> <p>For an iterative workflow:</p> <pre><code>nextflow.preview.recursion=true\n\nparams.input = \"$baseDir/data/hello.txt\"\n\nprocess tick {\n  input:\n    path 'input.txt'\n  output:\n    path 'result.txt'\n  script:\n    \"\"\"\n    cat input.txt &gt; result.txt\n    echo \"Task ${task.index} : tick\" &gt;&gt; result.txt\n    \"\"\"\n}\n\nprocess tock {\n  input:\n    path 'input.txt'\n  output:\n    path 'result.txt'\n  script:\n    \"\"\"\n    cat input.txt &gt; result.txt\n    echo \"Task ${task.index} : tock\" &gt;&gt; result.txt\n    \"\"\"\n}\n\nworkflow clock {\n  take: infile\n  main:\n    infile | tick | tock\n  emit:\n    tock.out\n}\n\nworkflow {\n  clock\n    .recurse(file(params.input))\n    .until { it -&gt; it.size() &gt; 100 }\n\n  clock\n    .out\n    .view(it -&gt; it.text)\n}\n</code></pre>"},{"location":"feedback-loop/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code># iterative process\nnextflow run nextflow-io/patterns/feedback-loop-process.nf\n\n# iterative workflow\nnextflow run nextflow-io/patterns/feedback-loop-workflow.nf\n</code></pre>"},{"location":"ignore-failing-process/","title":"Ignore failing process","text":""},{"location":"ignore-failing-process/#problem","title":"Problem","text":"<p>A task is expected to fail in some cases. You want to ignore the failure and continue the execution of the remaining tasks in the workflow. </p>"},{"location":"ignore-failing-process/#solution","title":"Solution","text":"<p>Use the process directive <code>errorStrategy 'ignore'</code> to ignore the error condition. </p>"},{"location":"ignore-failing-process/#code","title":"Code","text":"<pre><code>process foo {\n  errorStrategy 'ignore'\n  script:\n  '''\n  echo This is going to fail!\n  exit 1\n  '''\n}  \n\nprocess bar {\n  script:\n  '''\n  echo OK\n  '''\n}\n\nworkflow {\n  foo()\n  bar()\n}\n</code></pre>"},{"location":"ignore-failing-process/#run-it","title":"Run it","text":"<p>Run the script with the following command: </p> <pre><code>nextflow run nextflow-io/patterns/ignore-failing-process.nf \n</code></pre>"},{"location":"optional-input/","title":"Optional input","text":""},{"location":"optional-input/#problem","title":"Problem","text":"<p>One or more processes have an optional input file. </p>"},{"location":"optional-input/#solution","title":"Solution","text":"<p>Use a special file name to mark the absence of the file parameter.</p> <p>Create an empty file in <code>assets</code>: <pre><code>touch assets/NO_FILE\n</code></pre></p>"},{"location":"optional-input/#code","title":"Code","text":"<pre><code>params.inputs = \"$projectDir/data/prots/*{1,2,3}.fa\"\nparams.filter = \"$projectDir/assets/NO_FILE\"\n\nprocess foo {\n  debug true\n  input:\n  path seq\n  path opt\n\n  script:\n  def filter = opt.name != 'NO_FILE' ? \"--filter $opt\" : ''\n  \"\"\"\n  echo your_command --input $seq $filter\n  \"\"\"\n}\n\nworkflow {\n  prots_ch = Channel.fromPath(params.inputs, checkIfExists:true)\n  opt_file = file(params.filter, checkIfExists:true)\n\n  foo(prots_ch, opt_file)\n}\n</code></pre>"},{"location":"optional-input/#run-it","title":"Run it","text":"<p>Run the script with the following command: </p> <pre><code>nextflow run nextflow-io/patterns/optional-input.nf \n</code></pre> <p>Run the same script providing an optional file input:</p> <pre><code>nextflow run nextflow-io/patterns/optional-input.nf --filter foo.txt\n</code></pre>"},{"location":"optional-output/","title":"Optional output","text":""},{"location":"optional-output/#problem","title":"Problem","text":"<p>A task in your workflow is expected to not create an output file in some circumstances. </p>"},{"location":"optional-output/#solution","title":"Solution","text":"<p>Declare such output as an <code>optional</code> file. </p>"},{"location":"optional-output/#code","title":"Code","text":"<pre><code>process foo {\n  output: \n  path 'foo.txt', optional: true\n\n  script:\n  '''\n  touch foo.txt\n  '''\n}\n\nworkflow {\n  foo()\n}\n</code></pre>"},{"location":"optional-output/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code>nextflow run nextflow-io/patterns/optional-output.nf\n</code></pre>"},{"location":"process-collect/","title":"Process all outputs altogether","text":""},{"location":"process-collect/#problem","title":"Problem","text":"<p>You need to process all the outputs of an upstream task altogether. </p>"},{"location":"process-collect/#solution","title":"Solution","text":"<p>Use the collect operator to gather  all the outputs produced by the upstream task and emit them as a single output.  Then use the resulting channel as input for the downstream task.</p>"},{"location":"process-collect/#code","title":"Code","text":"<pre><code>process foo {\n  input:\n  path x\n  output:\n  path 'file.fq'\n  script:\n  \"\"\"\n  &lt; $x zcat &gt; file.fq\n  \"\"\"\n}\n\nprocess bar {\n  debug true   \n  input:\n  path '*.fq'\n  script:\n  \"\"\"\n  cat *.fq | head -n 50\n  \"\"\"\n}\n\nworkflow {\n  Channel.fromPath(\"$baseDir/data/reads/*_1.fq.gz\", checkIfExists: true) \\\n    | foo \\\n    | collect \\\n    | bar\n}\n</code></pre>"},{"location":"process-collect/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code>nextflow run nextflow-io/patterns/process-collect.nf\n</code></pre>"},{"location":"process-get-workdir/","title":"Get process work directory","text":""},{"location":"process-get-workdir/#problem","title":"Problem","text":"<p>A tool needs the explicit path of the current task work directory.</p>"},{"location":"process-get-workdir/#solution","title":"Solution","text":"<p>Use the <code>$PWD</code> Bash variable or the <code>pwd</code> command to retrieve the task working directory path.</p> <p>Note</p> <p>Make sure to escape the <code>$</code> variable placeholder when the command script is enclosed in double quote characters.</p>"},{"location":"process-get-workdir/#example","title":"Example","text":"<pre><code>process foo {\n  debug true\n  script:\n  \"\"\"\n  echo foo task path: \\$PWD\n  \"\"\" \n}\n\nprocess bar {\n  debug true\n  script:\n  '''\n  echo bar task path: $PWD\n  ''' \n}\n\nworkflow {\n  foo()\n  bar()\n}\n</code></pre>"},{"location":"process-get-workdir/#run-it","title":"Run it","text":"<p>The command run the script with an empty channel: </p> <pre><code>nextflow run nextflow-io/patterns/process-get-workdir.nf\n</code></pre> <p>Use the following command to provide the same script some input files, that prevents the process from being executed: </p> <pre><code>nextflow run nextflow-io/patterns/process-get-workdir.nf --inputs ../data/prots/\\*\n</code></pre>"},{"location":"process-into-groups/","title":"Process outputs into groups","text":""},{"location":"process-into-groups/#problem","title":"Problem","text":"<p>You need to process in the same batch all files that have a matching key in the file name.</p>"},{"location":"process-into-groups/#solution","title":"Solution","text":"<p>Use the map operator to associate each file with a key extracted from the file name. Then chain the resulting channel with the groupTuple operator to group together all files that have a matching key. Finally, use the resulting channel as input for the process.</p>"},{"location":"process-into-groups/#code","title":"Code","text":"<pre><code>params.reads = \"$baseDir/data/reads/*\"\n\nprocess foo {\n  debug true\n  input:\n  tuple val(key), file(samples)\n\n  script:\n  \"\"\"\n  echo your_command --batch $key --input $samples \n  \"\"\"\n} \n\nworkflow {\n  Channel.fromPath(params.reads, checkIfExists:true) \\\n    | map { file -&gt; \n      def key = file.name.toString().tokenize('_').get(0)\n      return tuple(key, file)\n    } \\\n    | groupTuple() \\\n    | foo\n}\n</code></pre>"},{"location":"process-into-groups/#run-it","title":"Run it","text":"<pre><code>nextflow run nextflow-io/patterns/process-into-groups.nf\n</code></pre>"},{"location":"process-per-csv-record/","title":"Process per CSV record","text":""},{"location":"process-per-csv-record/#problem","title":"Problem","text":"<p>You need to execute a task for each record in one or more CSV files.</p>"},{"location":"process-per-csv-record/#solution","title":"Solution","text":"<p>Read the CSV file line-by-line using the splitCsv operator, then use the map operator to return a tuple with the required field for each line and convert any string path to a file path object using the <code>file</code> function. Finally, use the resulting channel as input for the process. </p>"},{"location":"process-per-csv-record/#code","title":"Code","text":"<p>Given the file <code>index.csv</code> with the following content: </p> sampleId read1 read2 FC816RLABXX reads/110101_I315_FC816RLABXX_L1_HUMrutRGXDIAAPE_1.fq.gz reads/110101_I315_FC816RLABXX_L1_HUMrutRGXDIAAPE_2.fq.gz FC812MWABXX reads/110105_I186_FC812MWABXX_L8_HUMrutRGVDIABPE_1.fq.gz reads/110105_I186_FC812MWABXX_L8_HUMrutRGVDIABPE_2.fq.gz FC81DE8ABXX reads/110121_I288_FC81DE8ABXX_L3_HUMrutRGXDIAAPE_1.fq.gz reads/110121_I288_FC81DE8ABXX_L3_HUMrutRGXDIAAPE_2.fq.gz FC81DB5ABXX reads/110122_I329_FC81DB5ABXX_L6_HUMrutRGVDIAAPE_1.fq.gz reads/110122_I329_FC81DB5ABXX_L6_HUMrutRGVDIAAPE_2.fq.gz FC819P0ABXX reads/110128_I481_FC819P0ABXX_L5_HUMrutRGWDIAAPE_1.fq.gz reads/110128_I481_FC819P0ABXX_L5_HUMrutRGWDIAAPE_2.fq.gz <p>This workflow parses the file and executes a process for each line:</p> <pre><code>params.index = \"$baseDir/data/index.csv\"\n\nprocess foo {\n    debug true\n    input:\n    tuple val(sampleId), file(read1), file(read2)\n\n    script:\n    \"\"\"\n    echo your_command --sample $sampleId --reads $read1 $read2\n    \"\"\"\n}\n\nworkflow {\n    Channel.fromPath(params.index) \\\n        | splitCsv(header:true) \\\n        | map { row-&gt; tuple(row.sampleId, file(row.read1), file(row.read2)) } \\\n        | foo\n}\n</code></pre> <p>Note</p> <p>Relative paths are resolved by the <code>file</code> function against the execution directory. In practice, it is preferable to use absolute file paths.</p>"},{"location":"process-per-csv-record/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code>nextflow run nextflow-io/patterns/process-per-csv-record.nf\n</code></pre>"},{"location":"process-per-file-chunk/","title":"Process per file chunk","text":""},{"location":"process-per-file-chunk/#problem","title":"Problem","text":"<p>You need to split one or more input files into chunks and execute a task for each of them.</p>"},{"location":"process-per-file-chunk/#solution","title":"Solution","text":"<p>Use the splitText operator to split a file into chunks of a given size. Then use the resulting channel as input for the process implementing your task. </p> <p>Warning</p> <p>Chunks are kept in memory by default. When splitting big files, specify the parameter <code>file: true</code> to save the chunks into files. See the documentation for details.</p> <p>Splitter for specific file formats are available, e.g. splitFasta and splitFastq.</p>"},{"location":"process-per-file-chunk/#code","title":"Code","text":"<pre><code>params.infile = \"$baseDir/data/poem.txt\"\nparams.size = 5\n\nprocess foo {\n  debug true\n  input: \n  file x\n\n  script:\n  \"\"\"\n  rev $x | rev\n  \"\"\"\n}\n\nworkflow {\n  Channel.fromPath(params.infile) \\\n    | splitText(by: params.size) \\\n    | foo\n}\n</code></pre>"},{"location":"process-per-file-chunk/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code>nextflow run nextflow-io/patterns/process-per-file-chunk.nf\n</code></pre>"},{"location":"process-per-file-output/","title":"Process per file output","text":""},{"location":"process-per-file-output/#problem","title":"Problem","text":"<p>A task in your workflow produces two or more files at time. A downstream task needs to process each of these files independently.</p>"},{"location":"process-per-file-output/#solution","title":"Solution","text":"<p>Use the flatten operator to  transform the outputs of the upstream process to a channel that emits each file separately.  Then use this channel as input for the downstream process. </p>"},{"location":"process-per-file-output/#code","title":"Code","text":"<pre><code>process foo {\n  output:\n  path '*.txt'\n\n  script:\n  '''\n  echo Hello there! &gt; file1.txt\n  echo What a beautiful day &gt; file2.txt\n  echo I hope you are having fun! &gt; file3.txt \n  ''' \n}\n\nprocess bar {\n  debug true\n  input: \n  path x\n\n  script:\n  \"\"\"\n  cat $x\n  \"\"\"\n}\n\nworkflow {\n  foo | flatten | bar\n}\n</code></pre>"},{"location":"process-per-file-output/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code>nextflow run nextflow-io/patterns/process-per-file-output.nf\n</code></pre>"},{"location":"process-per-file-pairs/","title":"Process per file pairs","text":""},{"location":"process-per-file-pairs/#problem","title":"Problem","text":"<p>You need to process the files in a directory, grouping them by pairs. </p>"},{"location":"process-per-file-pairs/#solution","title":"Solution","text":"<p>Use the Channel.fromFilePairs method to create a channel that emits file pairs matching a glob pattern. The pattern must match a common prefix in the paired file names.</p> <p>The matching files are emitted as tuples in which the first element is the grouping key of the matching files and the second element is the file pair itself. </p>"},{"location":"process-per-file-pairs/#code","title":"Code","text":"<pre><code>process foo {\n  debug true\n\n  input:\n  tuple val(sampleId), file(reads)\n\n  script:\n  \"\"\"\n  echo your_command --sample $sampleId --reads $reads\n  \"\"\"\n}\n\nworkflow {\n  Channel.fromFilePairs(\"$baseDir/data/reads/*_{1,2}.fq.gz\", checkIfExists:true) \\\n    | foo\n}\n</code></pre>"},{"location":"process-per-file-pairs/#run-it","title":"Run it","text":"<pre><code>nextflow run nextflow-io/patterns/process-per-file-pairs.nf\n</code></pre>"},{"location":"process-per-file-pairs/#custom-grouping-strategy","title":"Custom grouping strategy","text":"<p>When necessary, it is possible to define a custom grouping strategy. A common use case is for alignment BAM files (<code>sample1.bam</code>) that come along with their index file. The difficulty is that the index is sometimes called <code>sample1.bai</code> and sometimes <code>sample1.bam.bai</code> depending on the software used. The following example can accommodate both cases. </p> <pre><code>process foo {\n  debug true\n  tag \"$sampleId\"\n\n  input:\n  tuple val(sampleId), file(bam)\n\n  script:\n  \"\"\"\n  echo your_command --sample ${sampleId} --bam ${sampleId}.bam\n  \"\"\"\n}\n\nworkflow {\n  Channel.fromFilePairs(\"$baseDir/data/alignment/*.{bam,bai}\", checkIfExists:true) { file -&gt; file.name.replaceAll(/.bam|.bai$/,'') } \\\n    | foo\n}\n</code></pre>"},{"location":"process-per-file-pairs/#run-it_1","title":"Run it","text":"<pre><code>nextflow run nextflow-io/patterns/process-per-file-pairs-custom.nf\n</code></pre>"},{"location":"process-per-file-path/","title":"Process per file path","text":""},{"location":"process-per-file-path/#problem","title":"Problem","text":"<p>You need to execute a task for each file that matches a glob pattern. </p>"},{"location":"process-per-file-path/#solution","title":"Solution","text":"<p>Use the Channel.fromPath method to create a channel emitting all files matching the glob pattern. Then, use the channel as input of the process implementing your task. </p>"},{"location":"process-per-file-path/#code","title":"Code","text":"<pre><code>process foo {\n  debug true\n  input:\n  path x\n\n  script:\n  \"\"\"\n  echo your_command --input $x\n  \"\"\"\n}\n\nworkflow {\n  foo(\"$baseDir/data/reads/*_1.fq.gz\")\n}\n</code></pre>"},{"location":"process-per-file-path/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code>nextflow run nextflow-io/patterns/process-per-file-path.nf\n</code></pre>"},{"location":"process-per-file-range/","title":"Process per file range","text":""},{"location":"process-per-file-range/#problem","title":"Problem","text":"<p>You need to execute a task over two or more series of files having a common index range. </p>"},{"location":"process-per-file-range/#solution","title":"Solution","text":"<p>Use the from method to define the range over which to repeat the task execution, then chain it with the map operator to associate each index with the corresponding input files. Finally, use the resulting channel as input for the process.</p>"},{"location":"process-per-file-range/#code","title":"Code","text":"<pre><code>process foo {\n  debug true\n  tag \"$sampleId\"\n\n  input: \n  tuple val(sampleId), file(indels), file(snps)\n\n  \"\"\"\n  echo foo_command --this $indels --that $snps\n  \"\"\"\n}\n\nworkflow {\n  Channel.from(1..23) \\\n    | map { chr -&gt; [\"sample${chr}\", file(\"/some/path/foo.${chr}.indels.vcf\"), file(\"/other/path/foo.snvs.${chr}.vcf\")] } \\\n    | foo\n}\n</code></pre>"},{"location":"process-per-file-range/#run-it","title":"Run it","text":"<pre><code>nextflow run nextflow-io/patterns/process-per-file-range.nf\n</code></pre>"},{"location":"process-when-empty/","title":"Process when empty","text":""},{"location":"process-when-empty/#problem","title":"Problem","text":"<p>You need to execute a process if a channel is empty. </p>"},{"location":"process-when-empty/#solution","title":"Solution","text":"<p>Use the ifEmpty operator to emit a marker value to trigger the execution of the process. </p>"},{"location":"process-when-empty/#example","title":"Example","text":"<pre><code>params.inputs = ''\n\nprocess foo {\n  debug true  \n  input:\n  val x\n  when:\n  x == 'EMPTY'\n\n  script:\n  '''\n  echo hello\n  ''' \n}\n\nworkflow {\n  reads_ch = params.inputs\n    ? Channel.fromPath(params.inputs, checkIfExists:true)\n    : Channel.empty()\n\n  reads_ch \\\n    | ifEmpty { 'EMPTY' } \\\n    | foo\n}\n</code></pre>"},{"location":"process-when-empty/#run-it","title":"Run it","text":"<p>Use the following command to run the script with an empty channel: </p> <pre><code>nextflow run nextflow-io/patterns/process-when-empty.nf\n</code></pre> <p>Use the following command to provide the same script some input files, which prevents the process from being executed: </p> <pre><code>nextflow run nextflow-io/patterns/process-when-empty.nf --inputs ../data/prots/\\*\n</code></pre>"},{"location":"publish-matching-glob/","title":"Store outputs matching a glob pattern","text":""},{"location":"publish-matching-glob/#problem","title":"Problem","text":"<p>A task in your workflow creates many output files that are required by a downstream task.  You want to store some of those files into separate directories depending on the file name.</p>"},{"location":"publish-matching-glob/#solution","title":"Solution","text":"<p>Use two or more publishDir directives to publish the output files into separate paths. For each directive specify a different glob pattern using the <code>pattern</code> option to store into each directory only the files that match the provided pattern.</p>"},{"location":"publish-matching-glob/#code","title":"Code","text":"<pre><code>params.reads = \"$baseDir/data/reads/*_{1,2}.fq.gz\"\nparams.outdir = 'my-results'\n\nprocess foo {\n  publishDir \"$params.outdir/$sampleId/counts\", pattern: \"*_counts.txt\"\n  publishDir \"$params.outdir/$sampleId/outlooks\", pattern: '*_outlook.txt'\n  publishDir \"$params.outdir/$sampleId/\", pattern: '*.fq'\n\n  input: \n    tuple val(sampleId), file('sample1.fq.gz'), file('sample2.fq.gz')\n  output: \n    path \"*\"\n  script:\n    \"\"\"\n    &lt; sample1.fq.gz zcat &gt; sample1.fq\n    &lt; sample2.fq.gz zcat &gt; sample2.fq\n\n    awk '{s++}END{print s/4}' sample1.fq &gt; sample1_counts.txt\n    awk '{s++}END{print s/4}' sample2.fq &gt; sample2_counts.txt\n\n    head -n 50 sample1.fq &gt; sample1_outlook.txt\n    head -n 50 sample2.fq &gt; sample2_outlook.txt\n    \"\"\"\n}\n\nworkflow {\n  Channel.fromFilePairs(params.reads, checkIfExists: true, flat: true) \\\n    | foo\n}\n</code></pre>"},{"location":"publish-matching-glob/#run-it","title":"Run it","text":"<p>Run the script with the following command:</p> <pre><code>nextflow run nextflow-io/patterns/publish-matching-glob.nf\n</code></pre>"},{"location":"publish-process-outputs/","title":"Store process outputs","text":""},{"location":"publish-process-outputs/#problem","title":"Problem","text":"<p>You need to store the outputs of one or more processes into a directory structure of your choice.</p>"},{"location":"publish-process-outputs/#solution","title":"Solution","text":"<p>Use the publishDir directive to define a custom directory where the process outputs should be saved.</p>"},{"location":"publish-process-outputs/#code","title":"Code","text":"<pre><code>params.reads = \"$baseDir/data/reads/*{1,2}.fq.gz\"\nparams.outdir = 'my-results'\n\nprocess foo {\n  publishDir \"$params.outdir/$sampleId\"\n  input:\n  tuple val(sampleId), file(samples)\n  output:\n  path '*.fq'\n\n  script:\n  \"\"\"\n  &lt; ${samples[0]} zcat &gt; sample_1.fq \n  &lt; ${samples[1]} zcat &gt; sample_2.fq \n  \"\"\"\n} \n\nworkflow {\n  Channel.fromFilePairs(params.reads, checkIfExists: true) \\\n    | foo\n}\n</code></pre>"},{"location":"publish-process-outputs/#run-it","title":"Run it","text":"<p>Run the script with the following command: </p> <pre><code>nextflow run nextflow-io/patterns/publish-process-outputs.nf \n</code></pre>"},{"location":"publish-rename-outputs/","title":"Store outputs renaming files","text":""},{"location":"publish-rename-outputs/#problem","title":"Problem","text":"<p>You need to save the outputs of a process to a directory, giving each file a name of your choice.</p>"},{"location":"publish-rename-outputs/#solution","title":"Solution","text":"<p>The publishDir allows you to save the process outputs in a directory of your choice. </p> <p>Use the <code>saveAs</code> option to give each file a name of your choice, providing a custom rule as a closure. </p>"},{"location":"publish-rename-outputs/#code","title":"Code","text":"<pre><code>process foo {\n  publishDir 'results', saveAs: { filename -&gt; \"foo_$filename\" }\n\n  output: \n  path '*.txt'\n\n  '''\n  touch this.txt\n  touch that.txt\n  '''\n}\n\nworkflow {\n  foo()\n}\n</code></pre>"},{"location":"publish-rename-outputs/#run-it","title":"Run it","text":"<pre><code>nextflow run nextflow-io/patterns/publish-rename-outputs.nf\n</code></pre>"},{"location":"publish-rename-outputs/#save-outputs-in-a-sub-directory","title":"Save outputs in a sub-directory","text":"<p>The same pattern can be used to store specific files in separate directories depending on the actual name. </p> <pre><code>process foo {\n  publishDir 'results', saveAs: { filename -&gt; filename.endsWith(\".zip\") ? \"zips/$filename\" : filename }\n\n  output: \n  path '*'\n\n  '''\n  touch this.txt\n  touch that.zip\n  '''\n}\n\nworkflow {\n  foo()\n}\n</code></pre> <p>Tip</p> <p>Relative paths are resolved against the <code>publishDir</code> store path. Use an absolute path to store files in a directory outside the <code>publishDir</code> store path. </p>"},{"location":"publish-rename-outputs/#run-it_1","title":"Run it","text":"<pre><code>nextflow run nextflow-io/patterns/publish-rename-outputs-subdirs.nf\n</code></pre>"},{"location":"skip-process-execution/","title":"Skip process execution","text":""},{"location":"skip-process-execution/#problem","title":"Problem","text":"<p>You have two sequential tasks in your workflow. When an optional flag is specified, the first task should be skipped and its input(s) should be processed by the second task.</p>"},{"location":"skip-process-execution/#solution","title":"Solution","text":"<p>Use an empty channel, created in a conditional expression, to skip the first process execution when an optional parameter is specified. Then, define the second process input as a mix of the first process output (when executed) and the input channel.</p>"},{"location":"skip-process-execution/#code","title":"Code","text":"<pre><code>params.skip = false\nparams.input = \"$baseDir/data/reads/sample.fq.gz\" \n\nprocess foo {\n  input:\n  path x\n\n  output:\n  file('*.fastq')\n\n  script:\n  \"\"\"\n  &lt; $x zcat &gt; ${x.simpleName}.fastq\n  \"\"\"\n}\n\nprocess bar {\n  debug true\n\n  input: \n  path x\n\n  script:\n  \"\"\"\n  echo your_command --input $x\n  \"\"\"\n}\n\nworkflow {\n  input_ch = Channel.fromPath(params.input)\n\n  (foo_ch, bar_ch) = params.skip\n    ? [Channel.empty(), input_ch] \n    : [input_ch, Channel.empty()]\n\n  foo_ch | foo | mix(bar_ch) | bar\n}\n</code></pre>"},{"location":"skip-process-execution/#run-it","title":"Run it","text":"<p>Use the the following command to execute the example:</p> <pre><code>nextflow run nextflow-io/patterns/skip-process-execution.nf\n</code></pre> <p>The processes <code>foo</code> and <code>bar</code> are executed. Run the same command with the <code>--skip</code> command line option:</p> <pre><code>nextflow run nextflow-io/patterns/skip-process-execution.nf --skip\n</code></pre> <p>This time only the <code>bar</code> process is executed.</p>"},{"location":"sort-filepairs-by-samplename/","title":"Sort FilePairs by sample name","text":""},{"location":"sort-filepairs-by-samplename/#problem","title":"Problem","text":"<p>You have many tuples with a sample name that works as an identifier and you want to sort the channel by the sample name.</p>"},{"location":"sort-filepairs-by-samplename/#solution","title":"Solution","text":"<p>Use the toSortedList and the flatMap operators to convert the channel to a sorted list, and then convert back to the original structure you get from the fromFilePairs channel factory.</p> <p>It's worth mentioning that the toSortedList operator is not scalable as it introduces a blocking point in the pipeline execution since to sort the elements of a channel, it needs to collect all of them first.</p> <p>The fromFilePairs channel factory in the code below will create a channel with tuple elements on the following format:</p> <pre><code>[\n  [samplec, [/path/to/my/files/samplec_1.fastq, /path/to/my/files/samplec_2.fastq]]\n  [sampleb, [/path/to/my/files/sampleb_1.fastq, /path/to/my/files/sampleb_2.fastq]]\n  [samplea, [/path/to/my/files/samplea_1.fastq, /path/to/my/files/samplea_2.fastq]]\n  [sampled, [/path/to/my/files/sampled_1.fastq, /path/to/my/files/sampled_2.fastq]]\n  [samplee, [/path/to/my/files/samplee_1.fastq, /path/to/my/files/samplee_2.fastq]]\n]\n</code></pre>"},{"location":"sort-filepairs-by-samplename/#code","title":"Code","text":"<pre><code>Channel\n  .fromFilePairs('/path/to/my/files/*_{1,2}.fastq')\n  // Sort the channel elements based on the first object of each tuple,\n  // that is, the sample name, and convert to a channel with a single\n  // element which is a list of tuples\n  .toSortedList( { a, b -&gt; a[0] &lt;=&gt; b[0] } ) // &lt;=&gt; is an operator for comparison\n  // flatten the single-element channel to a channel with as many elements\n  // as there are samples, which is the original structure provided by\n  // fromFilePairs\n  .flatMap()\n  // View the channel elements by printing it to the screen\n  .view()\n</code></pre>"},{"location":"sort-filepairs-by-samplename/#run-it","title":"Run it","text":"<p>Run the example using this command:</p> <pre><code>nextflow run nextflow-io/patterns/sort-filepairs-by-samplename.nf\n</code></pre>"},{"location":"state-dependency/","title":"State dependency","text":""},{"location":"state-dependency/#problem","title":"Problem","text":"<p>You need to synchronize the execution of two processes for which there isn't a data dependency, so that process <code>bar</code> is executed after the completion of process <code>foo</code>.  </p>"},{"location":"state-dependency/#solution","title":"Solution","text":"<p>Add an output channel to process <code>foo</code> that produces a ready signal. Then pass this channel as input to process <code>bar</code> in order to trigger its execution when <code>foo</code> completes.</p>"},{"location":"state-dependency/#code","title":"Code","text":"<pre><code>process foo {\n    output: \n    val true\n    script:\n    \"\"\"\n    echo your_command_here\n    \"\"\"\n}\n\nprocess bar {\n    input: \n    val ready\n    path fq\n    script:\n    \"\"\"\n    echo other_command_here --reads $fq\n    \"\"\"\n}\n\nworkflow {\n    reads_ch = Channel.fromPath(\"$baseDir/data/reads/11010*.fq.gz\", checkIfExists:true)\n\n    foo()\n    bar(foo.out, reads_ch)\n}\n</code></pre>"},{"location":"state-dependency/#run-it","title":"Run it","text":"<p>Run the example using this command:</p> <pre><code>nextflow run nextflow-io/patterns/state-dependency.nf\n</code></pre>"},{"location":"task-batching/","title":"Task batching","text":""},{"location":"task-batching/#problem","title":"Problem","text":"<p>You have many small tasks that you would like to process in batches to reduce job submission overhead.</p>"},{"location":"task-batching/#solution","title":"Solution","text":"<p>Use the buffer operator to collect your input channel into batches, then refactor the process to accept a list of inputs instead of one input. One job will be created for each batch instead of each task.</p>"},{"location":"task-batching/#code","title":"Code","text":"<pre><code>process foo {\n    input:\n    val indices\n\n    script:\n    \"\"\"\n    for INDEX in ${indices.join(' ')}; do\n        echo \"Hello from task \\${INDEX}!\"\n    done\n    \"\"\"\n}\n\nworkflow {\n    Channel.of(1..1000)\n        | buffer(size: 10, remainder: true)\n        | foo\n}\n</code></pre>"},{"location":"task-batching/#run-it","title":"Run it","text":"<p>Run the example using this command:</p> <pre><code>nextflow run nextflow-io/patterns/task-batching.nf\n</code></pre>"},{"location":"workflow-grouping/","title":"Workflow grouping","text":""},{"location":"workflow-grouping/#problem","title":"Problem","text":"<p>You have a subworkflow, and you would like to limit the number of parallel subworkflow executions.</p>"},{"location":"workflow-grouping/#solution","title":"Solution","text":"<p>For a single process, you could use the maxForks directive to limit the number of parallel process executions. For a subworkflow, you can achieve the same effect by merging the subworkflow's processes into a single process, and then using <code>maxForks</code> or the <code>executor.queueSize</code> config option.</p> <p>The following example is based on a \"diamond-shaped\" subworkflow, in order to show how to implement parallel steps in a Bash script. View the complete example to see the original subworkflow.</p>"},{"location":"workflow-grouping/#code","title":"Code","text":"<pre><code>params.n_groups = 10\nparams.queue_size = 2\n\nprocess diamond_merged {\n    maxForks params.queue_size\n\n    input:\n    val(index)\n\n    output:\n    tuple val(index), path('d.txt')\n\n    script:\n    \"\"\"\n    sleep 1\n\n    # process A\n    echo \"subworkflow ${index}, process A was here\" &gt;&gt; a.txt\n\n    # process B\n    process_b() {\n        cat a.txt &gt;&gt; b.txt\n        echo \"subworkflow ${index}, process B was here\" &gt;&gt; b.txt\n    }\n    process_b &amp;\n\n    # process C\n    process_c() {\n        cat a.txt &gt;&gt; c.txt\n        echo \"subworkflow ${index}, process C was here\" &gt;&gt; c.txt\n    }\n    process_c &amp;\n\n    wait\n\n    # process D\n    cat b.txt &gt;&gt; d.txt\n    cat c.txt &gt;&gt; d.txt\n    echo \"subworkflow ${index}, process D was here\" &gt;&gt; d.txt\n    \"\"\"\n}\n\nworkflow {\n    Channel.of(1..params.n_groups)\n      | diamond_merged\n}\n</code></pre>"},{"location":"workflow-grouping/#run-it","title":"Run it","text":"<p>Run the example using this command:</p> <pre><code>nextflow run nextflow-io/patterns/workflow-grouping.nf\n</code></pre>"}]}